{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8m1c_ymVf5ql"
   },
   "source": [
    "## WESPE_GAN: Weakly Supervised Photo Enhancer for Digital Cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pNB4ud0VwqU3"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lab4nSpFgMSr"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import glob\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jfwdZ77jJlM6",
    "outputId": "f99f3370-4c99-410d-b064-8e1533a03699"
   },
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "from keras.layers import Conv2D, BatchNormalization, Activation, Add, Flatten, Dense, Input, Lambda, DepthwiseConv2D\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cJO0MAoOw9Jn"
   },
   "outputs": [],
   "source": [
    "class WESPE_GAN(object):\n",
    "  \n",
    "  def __init__(self, input_shape):\n",
    "    self.input_shape = input_shape\n",
    "    self.batch_size = 30\n",
    "    self.patch_size = 96\n",
    "    self.w_content = 0.1\n",
    "    self.w_texture = 3\n",
    "    self.w_color = 20\n",
    "    self.w_tv = 1/400\n",
    "    self.optimizer = keras.optimizers.Adam(lr=1e-4)\n",
    "    \n",
    "    self.discriminator_Dc = self.build_discriminator(\"Dc\", \"blur\")\n",
    "    self.discriminator_Dt = self.build_discriminator(\"Dt\", \"grayscale\")\n",
    "    self.discriminator_Dc.compile(loss=keras.losses.binary_crossentropy, optimizer=self.optimizer, metrics=['accuracy'])\n",
    "    self.discriminator_Dt.compile(loss=keras.losses.binary_crossentropy, optimizer=self.optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    self.generator = self.build_generator(\"G\")\n",
    "    self.inverse_generator = self.build_generator(\"F\")\n",
    "    img = Input(shape=self.input_shape)\n",
    "    # dslr_img = Input(shape=self.input_shape)\n",
    "    enhanced_img = self.generator(img)\n",
    "    self.discriminator_Dc.trainable = False\n",
    "    self.discriminator_Dt.trainable = False\n",
    "    Dc_valid = self.discriminator_Dc(enhanced_img)\n",
    "    Dt_valid = self.discriminator_Dt(enhanced_img)\n",
    "    # Dc_valid_dslr = self.discriminator_Dc(dslr_img)\n",
    "    # Dt_valid_dslr = self.discriminator_Dt(dslr_img)\n",
    "    reconstructed_img = self.inverse_generator(enhanced_img)\n",
    "    self.combined_model = Model(inputs=img, outputs=[Dc_valid, Dt_valid, reconstructed_img])\n",
    "    self.combined_model.compile(loss=self.build_generator_loss(img, enhanced_img, reconstructed_img), optimizer=self.optimizer)\n",
    "  \n",
    "  def gaussian_kernel(self, kernlen=21, nsig=3, channels=1):\n",
    "    interval = (2*nsig+1.)/(kernlen)\n",
    "    x = np.linspace(-nsig-interval/2., nsig+interval/2., kernlen+1)\n",
    "    kern1d = np.diff(st.norm.cdf(x))\n",
    "    kernel_raw = np.sqrt(np.outer(kern1d, kern1d))\n",
    "    kernel = kernel_raw/kernel_raw.sum()\n",
    "    out_filter = np.array(kernel, dtype = np.float32)\n",
    "    out_filter = out_filter.reshape((kernlen, kernlen, 1, 1))\n",
    "    out_filter = np.repeat(out_filter, channels, axis = 2)\n",
    "    return out_filter\n",
    "\n",
    "  def gaussian_blur(self, X):\n",
    "    kernel_var = self.gaussian_kernel(21, 3, 3)\n",
    "    return Lambda(lambda x:tf.nn.depthwise_conv2d(x, kernel_var , [1, 1, 1, 1], padding='SAME'))(X)\n",
    "    \n",
    "  def rgb_to_grayscale(self, X):\n",
    "    return Lambda(lambda x:tf.image.rgb_to_grayscale(x))(X)\n",
    "  \n",
    "  def get_block(self, X, nn_name, block_number):\n",
    "    X_shortcut = X\n",
    "    X = Conv2D(64, kernel_size=3, strides=(1, 1), data_format=\"channels_last\", use_bias=True, padding=\"same\", kernel_initializer=glorot_uniform(seed=0), \n",
    "              name=nn_name+\"_conv\"+str(block_number)+\"_1\")(X)\n",
    "    X = BatchNormalization(axis=-1, center=True, scale=True, name=nn_name+\"_bn\"+str(block_number)+\"_1\")(X) # axis=-1 as data_format=\"channels_last\"\n",
    "    X = Activation('relu')(X)\n",
    "    X = Conv2D(64, kernel_size=3, strides=(1, 1), data_format=\"channels_last\", use_bias=True, padding=\"same\", kernel_initializer=glorot_uniform(seed=0), \n",
    "              name=nn_name+\"_conv\"+str(block_number)+\"_2\")(X)\n",
    "    X = BatchNormalization(axis=-1, center=True, scale=True, name=nn_name+\"_bn\"+str(block_number)+\"_2\")(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    return X\n",
    "  \n",
    "  def build_generator(self, nn_name):\n",
    "    X_Input = Input(self.input_shape)\n",
    "    X = Conv2D(64, kernel_size=9, strides=(1, 1), data_format=\"channels_last\", activation=\"relu\", use_bias=True, padding=\"same\", \n",
    "               kernel_initializer=glorot_uniform(seed=0), name=nn_name+\"_conv0\")(X_Input)\n",
    "    X = self.get_block(X, nn_name, 1)\n",
    "    X = self.get_block(X, nn_name, 2)\n",
    "    X = self.get_block(X, nn_name, 3)\n",
    "    X = self.get_block(X, nn_name, 4)\n",
    "    X = Conv2D(64, kernel_size=3, strides=(1, 1), data_format=\"channels_last\", activation=\"relu\", use_bias=True, padding=\"same\", \n",
    "               kernel_initializer=glorot_uniform(seed=0), name=nn_name+\"_conv5\")(X)\n",
    "    X = Conv2D(64, kernel_size=3, strides=(1, 1), data_format=\"channels_last\", activation=\"relu\", use_bias=True, padding=\"same\", \n",
    "               kernel_initializer=glorot_uniform(seed=0), name=nn_name+\"_conv6\")(X)\n",
    "    X = Conv2D(64, kernel_size=9, strides=(1, 1), data_format=\"channels_last\", activation=\"relu\", use_bias=True, padding=\"same\", \n",
    "               kernel_initializer=glorot_uniform(seed=0), name=nn_name+\"_conv7\")(X)\n",
    "    X = Conv2D(3, kernel_size=1, strides=(1, 1), data_format=\"channels_last\", use_bias=True, padding=\"same\", \n",
    "               kernel_initializer=glorot_uniform(seed=0), name=nn_name+\"_conv8\")(X)\n",
    "    model = Model(inputs=X_Input, outputs=X, name='Network_'+nn_name)\n",
    "    return model\n",
    "  \n",
    "  def build_discriminator(self, nn_name, preprocess):\n",
    "    X_Input = Input((96, 96, 3))\n",
    "    if preprocess == \"grayscale\":\n",
    "        X = self.rgb_to_grayscale(X_Input)\n",
    "    elif preprocess == 'blur':\n",
    "        X = self.gaussian_blur(X_Input)\n",
    "    else:\n",
    "        X = X_Input\n",
    "    X = Conv2D(48, kernel_size=11, strides=(4, 4), data_format=\"channels_last\", activation=keras.layers.LeakyReLU(alpha=0.2), use_bias=True,\n",
    "               padding=\"same\", kernel_initializer=glorot_uniform(seed=0), name=nn_name+\"_conv0\")(X)\n",
    "    X = Conv2D(128, kernel_size=5, strides=(2, 2), data_format=\"channels_last\", use_bias=True, padding=\"same\", \n",
    "               kernel_initializer=glorot_uniform(seed=0), name=nn_name+\"_conv1\")(X)\n",
    "    X = BatchNormalization(axis=-1, center=True, scale=True, name=nn_name+\"_bn1\")(X)\n",
    "    X = keras.layers.LeakyReLU(alpha=0.2)(X)\n",
    "    X = Conv2D(192, kernel_size=3, strides=(1, 1), data_format=\"channels_last\", use_bias=True, padding=\"same\", \n",
    "               kernel_initializer=glorot_uniform(seed=0), name=nn_name+\"_conv2\")(X)\n",
    "    X = BatchNormalization(axis=-1, center=True, scale=True, name=nn_name+\"_bn2\")(X)\n",
    "    X = keras.layers.LeakyReLU(alpha=0.2)(X)\n",
    "    X = Conv2D(192, kernel_size=3, strides=(1, 1), data_format=\"channels_last\", use_bias=True, padding=\"same\", \n",
    "               kernel_initializer=glorot_uniform(seed=0), name=nn_name+\"_conv3\")(X)\n",
    "    X = BatchNormalization(axis=-1, center=True, scale=True, name=nn_name+\"_bn3\")(X)\n",
    "    X = keras.layers.LeakyReLU(alpha=0.2)(X)\n",
    "    X = Conv2D(128, kernel_size=3, strides=(2, 2), data_format=\"channels_last\", use_bias=True, padding=\"same\", \n",
    "               kernel_initializer=glorot_uniform(seed=0), name=nn_name+\"_conv4\")(X)\n",
    "    X = BatchNormalization(axis=-1, center=True, scale=True, name=nn_name+\"_bn4\")(X)\n",
    "    X = keras.layers.LeakyReLU(alpha=0.2)(X)\n",
    "    X = Flatten(data_format=\"channels_last\")(X)\n",
    "    X = Dense(1024, activation=keras.layers.LeakyReLU(alpha=0.2))(X)\n",
    "    X_out = Dense(1, activation='sigmoid')(X)\n",
    "    model = Model(X_Input, X_out, name='Network_'+nn_name)\n",
    "    return model\n",
    "  \n",
    "  def build_generator_loss(self, img, enhanced_img, reconstructed_img):\n",
    "    mobile_net_v2 = keras.applications.mobilenet_v2.MobileNetV2(input_shape=(96, 96, 3), include_top=False, weights='imagenet')\n",
    "    mobile_net_v2.trainable = False\n",
    "    mobile_net_v2_truncated = Model(mobile_net_v2.input, mobile_net_v2.get_layer('Conv_1').output)\n",
    "    content_loss = keras.backend.mean(keras.backend.square(mobile_net_v2_truncated(img) - mobile_net_v2_truncated(reconstructed_img)))\n",
    "    tv_loss = keras.backend.mean(tf.image.total_variation(enhanced_img))\n",
    "    \n",
    "    def my_loss(y_true, y_pred):\n",
    "      color_loss = keras.backend.mean(keras.losses.binary_crossentropy(y_true[0], y_pred[0]))\n",
    "      texture_loss = keras.backend.mean(keras.losses.binary_crossentropy(y_true[1], y_pred[1]))\n",
    "      generator_loss = self.w_content * content_loss + self.w_color * color_loss + self.w_texture * texture_loss + self.w_tv * tv_loss\n",
    "      return generator_loss\n",
    "    \n",
    "    return my_loss\n",
    "  \n",
    "  def preprocess(self, img):\n",
    "    mean_RGB = np.array([123.68, 116.779, 103.939])\n",
    "    return (img - mean_RGB)/255\n",
    "  \n",
    "  def load_dataset(self, phone_dir, dslr_dir):\n",
    "    train_imgs_iphone = [phone_dir+'{}.jpg'.format(i) for i in range(0, 3500)]\n",
    "    train_imgs_dslr = [dslr_dir+'{}.jpg'.format(i) for i in range(0, 3500)]\n",
    "    phone_images = []\n",
    "    dslr_images = []\n",
    "    for file1, file2 in zip(train_imgs_iphone, train_imgs_dslr):\n",
    "      try:\n",
    "        phone_images.append(cv2.resize(cv2.imread(file1, cv2.IMREAD_COLOR), (96, 96), interpolation=cv2.INTER_AREA))\n",
    "        dslr_images.append(cv2.resize(cv2.imread(file2, cv2.IMREAD_COLOR), (96, 96), interpolation=cv2.INTER_AREA)) \n",
    "      except:\n",
    "        continue\n",
    "    print(len(phone_images))\n",
    "    print(len(dslr_images))\n",
    "    return phone_images, dslr_images\n",
    "\n",
    "  def get_batch(self, phone_images, dslr_images, augmentation):\n",
    "    phone_batch = np.zeros([self.batch_size, self.patch_size, self.patch_size, 3], dtype = 'float32')\n",
    "    dslr_batch = np.zeros([self.batch_size, self.patch_size, self.patch_size, 3], dtype = 'float32')\n",
    "    for img_no in range(self.batch_size):\n",
    "        random_index = np.random.randint(len(phone_images))\n",
    "        phone_patch = phone_images[random_index]\n",
    "        dslr_patch = dslr_images[random_index]\n",
    "        # randomly flip, rotate patch (assuming that the patch shape is square)\n",
    "        if augmentation == True:\n",
    "            probability = np.random.rand()\n",
    "            if probability > 0.5:\n",
    "                phone_patch = np.flip(phone_patch, axis = 0)\n",
    "                dslr_patch = np.flip(dslr_patch, axis = 0)\n",
    "            probability = np.random.rand()\n",
    "            if probability > 0.5:\n",
    "                phone_patch = np.flip(phone_patch, axis = 1)\n",
    "                dslr_patch = np.flip(dslr_patch, axis = 1)\n",
    "            probability = np.random.rand()\n",
    "            if probability > 0.5:\n",
    "                phone_patch = np.rot90(phone_patch)\n",
    "                dslr_patch = np.rot90(dslr_patch)\n",
    "        phone_batch[img_no,:,:,:] = self.preprocess(phone_patch)\n",
    "        dslr_batch[img_no,:,:,:] = self.preprocess(dslr_patch)\n",
    "    return phone_batch, dslr_batch\n",
    "  \n",
    "  def train(self, epochs=5000, batch_size=30, save_interval=20):\n",
    "    phone_images, dslr_images = self.load_dataset('../input/train/train/iphone/', '../input/train/train/canon/')\n",
    "    valid = np.ones((self.batch_size, 1))\n",
    "    fake = np.zeros((self.batch_size, 1))\n",
    "    print(self.discriminator_Dc.metrics_names)\n",
    "    print(self.discriminator_Dt.metrics_names)\n",
    "    print(self.combined_model.metrics_names)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # print(\"Epoch: \", epoch)\n",
    "        # batch_X = tf.placeholder(dtype=tf.float32,shape=(self.batch_size, self.patch_size, self.patch_size, 3))\n",
    "        # blur_op = self.gaussian_blur(batch_X)\n",
    "        # sess = tf.Session()\n",
    "        # blurred_enhanced_phone_batch = sess.run(blur_op, feed_dict={batch_X: enhanced_phone_batch})\n",
    "        # blurred_dslr_batch = sess.run(blur_op, feed_dict={batch_X: dslr_batch})\n",
    "        # sess.close()\n",
    "        # grayscale_enhanced_phone_batch = [color.rgb2gray(img) for img in enhanced_phone_batch]\n",
    "        # grayscale_dslr_batch = [color.rgb2gray(img) for img in dslr_batch]\n",
    "        self.discriminator_Dc.trainable = True\n",
    "        self.discriminator_Dt.trainable = True\n",
    "        for j in range(1):\n",
    "            phone_batch, dslr_batch = self.get_batch(phone_images, dslr_images, True)\n",
    "            enhanced_phone_batch = self.generator.predict(phone_batch)\n",
    "            Dc_loss_real = self.discriminator_Dc.train_on_batch(dslr_batch, valid)\n",
    "            Dc_loss_fake = self.discriminator_Dc.train_on_batch(enhanced_phone_batch, fake)\n",
    "            Dt_loss_real = self.discriminator_Dt.train_on_batch(dslr_batch, valid)\n",
    "            Dt_loss_fake = self.discriminator_Dt.train_on_batch(enhanced_phone_batch, fake)\n",
    "        self.discriminator_Dc.trainable = False\n",
    "        self.discriminator_Dt.trainable = False\n",
    "        for j in range(4):\n",
    "            # phone_batch, dslr_batch = self.get_batch(phone_images, dslr_images, True)\n",
    "            phone_batch, dslr_batch = self.get_batch(phone_images, dslr_images, True) # Can change False to True\n",
    "            Dc_pred = self.discriminator_Dc.predict(dslr_batch)\n",
    "            Dt_pred = self.discriminator_Dt.predict(dslr_batch)\n",
    "            gen_loss = self.combined_model.train_on_batch([phone_batch], [Dc_pred, Dt_pred, dslr_batch])\n",
    "        if epoch % 100 is  99:\n",
    "            print(\"--------------------------------------------{0}----------------------------------------\".format(epoch))\n",
    "            print('Dc_loss_real:', Dc_loss_real)\n",
    "            print('Dc_loss_fake:', Dc_loss_fake)\n",
    "            print('Dt_loss_real:', Dt_loss_real)\n",
    "            print('Dt_loss_fake:', Dt_loss_fake)\n",
    "            print(\"Generator Loss: \", gen_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "Na3v5HkHKlL3",
    "outputId": "b7dbe142-5dd7-4118-be68-23c8a9d6601c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    }
   ],
   "source": [
    "gan_model = WESPE_GAN((96, 96, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'G_conv0_7/kernel:0' shape=(9, 9, 3, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'G_conv0_7/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'G_conv1_1_7/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'G_conv1_1_7/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'G_bn1_1_7/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'G_bn1_1_7/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'G_conv1_2_7/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'G_conv1_2_7/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'G_bn1_2_7/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'G_bn1_2_7/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'G_conv2_1_7/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'G_conv2_1_7/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'G_bn2_1_7/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'G_bn2_1_7/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'G_conv2_2_7/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'G_conv2_2_7/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'G_bn2_2_7/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'G_bn2_2_7/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'G_conv3_1_7/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'G_conv3_1_7/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'G_bn3_1_7/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'G_bn3_1_7/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'G_conv3_2_7/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'G_conv3_2_7/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'G_bn3_2_7/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'G_bn3_2_7/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'G_conv4_1_7/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'G_conv4_1_7/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'G_bn4_1_7/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'G_bn4_1_7/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'G_conv4_2_7/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'G_conv4_2_7/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'G_bn4_2_7/gamma:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'G_bn4_2_7/beta:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'G_conv5_7/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'G_conv5_7/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'G_conv6_7/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'G_conv6_7/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'G_conv7_7/kernel:0' shape=(9, 9, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'G_conv7_7/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'G_conv8_7/kernel:0' shape=(1, 1, 64, 3) dtype=float32_ref>,\n",
       " <tf.Variable 'G_conv8_7/bias:0' shape=(3,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan_model.generator.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_45 (InputLayer)           (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "G_conv0 (Conv2D)                (None, 96, 96, 64)   15616       input_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "G_conv1_1 (Conv2D)              (None, 96, 96, 64)   36928       G_conv0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "G_bn1_1 (BatchNormalization)    (None, 96, 96, 64)   256         G_conv1_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 96, 96, 64)   0           G_bn1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "G_conv1_2 (Conv2D)              (None, 96, 96, 64)   36928       activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "G_bn1_2 (BatchNormalization)    (None, 96, 96, 64)   256         G_conv1_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 96, 96, 64)   0           G_bn1_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_57 (Add)                    (None, 96, 96, 64)   0           activation_114[0][0]             \n",
      "                                                                 G_conv0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "G_conv2_1 (Conv2D)              (None, 96, 96, 64)   36928       add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "G_bn2_1 (BatchNormalization)    (None, 96, 96, 64)   256         G_conv2_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 96, 96, 64)   0           G_bn2_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "G_conv2_2 (Conv2D)              (None, 96, 96, 64)   36928       activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "G_bn2_2 (BatchNormalization)    (None, 96, 96, 64)   256         G_conv2_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 96, 96, 64)   0           G_bn2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_58 (Add)                    (None, 96, 96, 64)   0           activation_116[0][0]             \n",
      "                                                                 add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "G_conv3_1 (Conv2D)              (None, 96, 96, 64)   36928       add_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "G_bn3_1 (BatchNormalization)    (None, 96, 96, 64)   256         G_conv3_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 96, 96, 64)   0           G_bn3_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "G_conv3_2 (Conv2D)              (None, 96, 96, 64)   36928       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "G_bn3_2 (BatchNormalization)    (None, 96, 96, 64)   256         G_conv3_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 96, 96, 64)   0           G_bn3_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_59 (Add)                    (None, 96, 96, 64)   0           activation_118[0][0]             \n",
      "                                                                 add_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "G_conv4_1 (Conv2D)              (None, 96, 96, 64)   36928       add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "G_bn4_1 (BatchNormalization)    (None, 96, 96, 64)   256         G_conv4_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 96, 96, 64)   0           G_bn4_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "G_conv4_2 (Conv2D)              (None, 96, 96, 64)   36928       activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "G_bn4_2 (BatchNormalization)    (None, 96, 96, 64)   256         G_conv4_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 96, 96, 64)   0           G_bn4_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_60 (Add)                    (None, 96, 96, 64)   0           activation_120[0][0]             \n",
      "                                                                 add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "G_conv5 (Conv2D)                (None, 96, 96, 64)   36928       add_60[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "G_conv6 (Conv2D)                (None, 96, 96, 64)   36928       G_conv5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "G_conv7 (Conv2D)                (None, 96, 96, 64)   331840      G_conv6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "G_conv8 (Conv2D)                (None, 96, 96, 3)    195         G_conv7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 718,979\n",
      "Trainable params: 717,955\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan_model.generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_46 (InputLayer)           (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "F_conv0 (Conv2D)                (None, 96, 96, 64)   15616       input_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "F_conv1_1 (Conv2D)              (None, 96, 96, 64)   36928       F_conv0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "F_bn1_1 (BatchNormalization)    (None, 96, 96, 64)   256         F_conv1_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 96, 96, 64)   0           F_bn1_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "F_conv1_2 (Conv2D)              (None, 96, 96, 64)   36928       activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "F_bn1_2 (BatchNormalization)    (None, 96, 96, 64)   256         F_conv1_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 96, 96, 64)   0           F_bn1_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_61 (Add)                    (None, 96, 96, 64)   0           activation_122[0][0]             \n",
      "                                                                 F_conv0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "F_conv2_1 (Conv2D)              (None, 96, 96, 64)   36928       add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "F_bn2_1 (BatchNormalization)    (None, 96, 96, 64)   256         F_conv2_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 96, 96, 64)   0           F_bn2_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "F_conv2_2 (Conv2D)              (None, 96, 96, 64)   36928       activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "F_bn2_2 (BatchNormalization)    (None, 96, 96, 64)   256         F_conv2_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 96, 96, 64)   0           F_bn2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_62 (Add)                    (None, 96, 96, 64)   0           activation_124[0][0]             \n",
      "                                                                 add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "F_conv3_1 (Conv2D)              (None, 96, 96, 64)   36928       add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "F_bn3_1 (BatchNormalization)    (None, 96, 96, 64)   256         F_conv3_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 96, 96, 64)   0           F_bn3_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "F_conv3_2 (Conv2D)              (None, 96, 96, 64)   36928       activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "F_bn3_2 (BatchNormalization)    (None, 96, 96, 64)   256         F_conv3_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 96, 96, 64)   0           F_bn3_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_63 (Add)                    (None, 96, 96, 64)   0           activation_126[0][0]             \n",
      "                                                                 add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "F_conv4_1 (Conv2D)              (None, 96, 96, 64)   36928       add_63[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "F_bn4_1 (BatchNormalization)    (None, 96, 96, 64)   256         F_conv4_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 96, 96, 64)   0           F_bn4_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "F_conv4_2 (Conv2D)              (None, 96, 96, 64)   36928       activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "F_bn4_2 (BatchNormalization)    (None, 96, 96, 64)   256         F_conv4_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 96, 96, 64)   0           F_bn4_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_64 (Add)                    (None, 96, 96, 64)   0           activation_128[0][0]             \n",
      "                                                                 add_63[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "F_conv5 (Conv2D)                (None, 96, 96, 64)   36928       add_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "F_conv6 (Conv2D)                (None, 96, 96, 64)   36928       F_conv5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "F_conv7 (Conv2D)                (None, 96, 96, 64)   331840      F_conv6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "F_conv8 (Conv2D)                (None, 96, 96, 3)    195         F_conv7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 718,979\n",
      "Trainable params: 717,955\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan_model.inverse_generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_47 (InputLayer)           (None, 96, 96, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Network_G (Model)               (None, 96, 96, 3)    718979      input_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Network_Dc (Model)              (None, 1)            5669057     Network_G[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Network_Dt (Model)              (None, 1)            5657441     Network_G[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Network_F (Model)               (None, 96, 96, 3)    718979      Network_G[1][0]                  \n",
      "==================================================================================================\n",
      "Total params: 12,764,456\n",
      "Trainable params: 1,435,910\n",
      "Non-trainable params: 11,328,546\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan_model.combined_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_43 (InputLayer)        (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "lambda_15 (Lambda)           (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "Dc_conv0 (Conv2D)            (None, 24, 24, 48)        17472     \n",
      "_________________________________________________________________\n",
      "Dc_conv1 (Conv2D)            (None, 12, 12, 128)       153728    \n",
      "_________________________________________________________________\n",
      "Dc_bn1 (BatchNormalization)  (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_86 (LeakyReLU)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "Dc_conv2 (Conv2D)            (None, 12, 12, 192)       221376    \n",
      "_________________________________________________________________\n",
      "Dc_bn2 (BatchNormalization)  (None, 12, 12, 192)       768       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_87 (LeakyReLU)   (None, 12, 12, 192)       0         \n",
      "_________________________________________________________________\n",
      "Dc_conv3 (Conv2D)            (None, 12, 12, 192)       331968    \n",
      "_________________________________________________________________\n",
      "Dc_bn3 (BatchNormalization)  (None, 12, 12, 192)       768       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_88 (LeakyReLU)   (None, 12, 12, 192)       0         \n",
      "_________________________________________________________________\n",
      "Dc_conv4 (Conv2D)            (None, 6, 6, 128)         221312    \n",
      "_________________________________________________________________\n",
      "Dc_bn4 (BatchNormalization)  (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_89 (LeakyReLU)   (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1024)              4719616   \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 11,336,834\n",
      "Trainable params: 5,667,777\n",
      "Non-trainable params: 5,669,057\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "gan_model.discriminator_Dc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_44 (InputLayer)        (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "lambda_16 (Lambda)           (None, 96, 96, 1)         0         \n",
      "_________________________________________________________________\n",
      "Dt_conv0 (Conv2D)            (None, 24, 24, 48)        5856      \n",
      "_________________________________________________________________\n",
      "Dt_conv1 (Conv2D)            (None, 12, 12, 128)       153728    \n",
      "_________________________________________________________________\n",
      "Dt_bn1 (BatchNormalization)  (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_92 (LeakyReLU)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "Dt_conv2 (Conv2D)            (None, 12, 12, 192)       221376    \n",
      "_________________________________________________________________\n",
      "Dt_bn2 (BatchNormalization)  (None, 12, 12, 192)       768       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_93 (LeakyReLU)   (None, 12, 12, 192)       0         \n",
      "_________________________________________________________________\n",
      "Dt_conv3 (Conv2D)            (None, 12, 12, 192)       331968    \n",
      "_________________________________________________________________\n",
      "Dt_bn3 (BatchNormalization)  (None, 12, 12, 192)       768       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_94 (LeakyReLU)   (None, 12, 12, 192)       0         \n",
      "_________________________________________________________________\n",
      "Dt_conv4 (Conv2D)            (None, 6, 6, 128)         221312    \n",
      "_________________________________________________________________\n",
      "Dt_bn4 (BatchNormalization)  (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_95 (LeakyReLU)   (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1024)              4719616   \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 11,313,602\n",
      "Trainable params: 5,656,161\n",
      "Non-trainable params: 5,657,441\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "gan_model.discriminator_Dt.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j2piw5Uw6RnN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500\n",
      "3500\n",
      "['loss', 'acc']\n",
      "['loss', 'acc']\n",
      "['loss', 'Network_Dc_loss', 'Network_Dt_loss', 'Network_F_loss']\n",
      "--------------------------------------------99----------------------------------------\n",
      "Dc_loss_real: [3.7133937e-06, 1.0]\n",
      "Dc_loss_fake: [0.0003523166, 1.0]\n",
      "Dt_loss_real: [0.38510722, 0.76666665]\n",
      "Dt_loss_fake: [0.008477378, 1.0]\n",
      "Generator Loss:  [42.86021, 1.6617748, 22.82245, 18.375984]\n",
      "--------------------------------------------199----------------------------------------\n",
      "Dc_loss_real: [1.3987433e-06, 1.0]\n",
      "Dc_loss_fake: [0.00829271, 1.0]\n",
      "Dt_loss_real: [0.19569421, 0.96666664]\n",
      "Dt_loss_fake: [0.5290775, 0.6666667]\n",
      "Generator Loss:  [-16.266788, 21.035378, 18.08718, -55.389347]\n",
      "--------------------------------------------299----------------------------------------\n",
      "Dc_loss_real: [1.3797901e-05, 1.0]\n",
      "Dc_loss_fake: [5.630855e-07, 1.0]\n",
      "Dt_loss_real: [0.44486132, 0.76666665]\n",
      "Dt_loss_fake: [0.50736576, 0.8]\n",
      "Generator Loss:  [86.95972, 1.9448267, 42.317368, 42.697517]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-c06e18364757>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgan_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-54-161fb83f91a5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size, save_interval)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mDc_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator_Dc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdslr_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0mDt_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator_Dt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdslr_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mgen_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombined_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphone_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mDc_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDt_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdslr_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;32mis\u001b[0m  \u001b[0;36m99\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--------------------------------------------{0}----------------------------------------\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gan_model.train(epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "https://stackoverflow.com/questions/38553927/batch-normalization-in-convolutional-neural-network  \n",
    "https://github.com/eriklindernoren/Keras-GAN/blob/master/dcgan/dcgan.py  \n",
    "https://github.com/JuheonYi/WESPE-TensorFlow  \n",
    "https://keras.io/applications/  \n",
    "https://medium.com/tensorflow/neural-style-transfer-creating-art-with-deep-learning-using-tf-keras-and-eager-execution-7d541ac31398  \n",
    "https://gogul09.github.io/software/flower-recognition-deep-learning   \n",
    "https://github.com/keras-team/keras-applications/blob/master/keras_applications/mobilenet_v2.py\n",
    "https://www.pyimagesearch.com/2018/12/24/how-to-use-keras-fit-and-fit_generator-a-hands-on-tutorial/  \n",
    "https://github.com/keras-team/keras/issues/7491  \n",
    "https://keras.io/getting-started/functional-api-guide/#multi-input-and-multi-output-models  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "WESPE_Project0.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
